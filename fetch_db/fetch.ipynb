{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "\n",
    "from tqdm import tqdm\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['work.sparql',\n",
       " 'school.sparql',\n",
       " 'main_philosophers.sparql',\n",
       " 'era.sparql',\n",
       " 'birthPlace.sparql',\n",
       " 'notableIdea.sparql',\n",
       " 'mainInterest.sparql',\n",
       " 'influenced.sparql']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QUERY_DIR = 'queries'\n",
    "DATA_DIR = '_data'\n",
    "\n",
    "shutil.rmtree(os.path.join(os.getcwd(), DATA_DIR), ignore_errors=True)\n",
    "os.makedirs(os.path.join(os.getcwd(), DATA_DIR), exist_ok=True)\n",
    "queries = []\n",
    "names = []\n",
    "\n",
    "for filename in glob.glob(f'./{QUERY_DIR}/*.sparql'):\n",
    "    with open(filename, 'r') as f:\n",
    "        names.append(os.path.basename(filename))\n",
    "        queries.append(f.read())\n",
    "        \n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'default-graph-uri': 'http://dbpedia.org',\n",
       " 'query': \"SELECT * WHERE {\\n?object a <http://dbpedia.org/ontology/Philosopher> .\\n?object dbo:wikiPageID ?wikiPageID .\\n?work dbo:author ?object .\\nOPTIONAL {?work foaf:name ?work_name} .\\nOPTIONAL {?work dbo:abstract ?work_abstract FILTER(lang(?work_abstract) = 'en')} .\\nOPTIONAL {?work dbo:wikiPageID ?work_wikiPageID} .\\nOPTIONAL {?work dbp:pubDate ?work_pubDate} .\\nOPTIONAL {?work dbp:language ?work_language} .\\n} ORDER BY ASC(?object)\\n LIMIT 10000 OFFSET 10000\",\n",
       " 'format': 'application/sparql-results+json',\n",
       " 'CXML_redir_for_subjs': 121,\n",
       " 'CXML_redir_for_hrefs': None,\n",
       " 'timeout': 30000,\n",
       " 'run': 'Run Query '}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def params(query, limit, offset):\n",
    "    q = query + f' LIMIT {limit} OFFSET {offset}'\n",
    "    return {\n",
    "        \"default-graph-uri\": \"http://dbpedia.org\",\n",
    "        \"query\": q,\n",
    "        \"format\": \"application/sparql-results+json\",\n",
    "        \"CXML_redir_for_subjs\": 121,\n",
    "        \"CXML_redir_for_hrefs\": None,\n",
    "        \"timeout\": 30000,\n",
    "        \"run\": \"Run Query \"\n",
    "    }\n",
    "\n",
    "params(queries[0], 10000, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch(query, name):\n",
    "    data = None\n",
    "    limit = 10000\n",
    "    i = 0\n",
    "    with tqdm(desc=name) as bar:\n",
    "        while True:\n",
    "            r = requests.get('http://dbpedia.org/sparql/', params=params(query, limit, i * limit))\n",
    "            if data is None:\n",
    "                data = r.json()\n",
    "                upd = len(data[\"results\"][\"bindings\"])\n",
    "            else:\n",
    "                bindings = r.json()[\"results\"][\"bindings\"]\n",
    "                upd = len(bindings)\n",
    "                if len(bindings) > 0:\n",
    "                    data[\"results\"][\"bindings\"].extend(bindings)\n",
    "                else:\n",
    "                    break\n",
    "            i += 1\n",
    "            bar.update(upd)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(query, name):\n",
    "    name = name + '_' + datetime.now().strftime(\"%c\") + '.json'\n",
    "    name = os.path.join(DATA_DIR, name)\n",
    "    data = fetch(query, name)\n",
    "    with open(name, 'w') as f:\n",
    "        json.dump(data, f)\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_data/work.sparql_Sun Mar 15 21:35:07 2020.json: 961it [00:03, 275.40it/s]\n",
      "_data/school.sparql_Sun Mar 15 21:35:10 2020.json: 2076it [00:11, 181.57it/s]\n",
      "_data/main_philosophers.sparql_Sun Mar 15 21:35:22 2020.json: 5149it [00:20, 254.81it/s]\n",
      "_data/era.sparql_Sun Mar 15 21:35:42 2020.json: 1316it [00:06, 217.74it/s]\n",
      "_data/birthPlace.sparql_Sun Mar 15 21:35:49 2020.json: 4742it [00:10, 452.78it/s]\n",
      "_data/notableIdea.sparql_Sun Mar 15 21:35:59 2020.json: 1488it [00:05, 248.79it/s]\n",
      "_data/mainInterest.sparql_Sun Mar 15 21:36:05 2020.json: 4282it [00:20, 206.43it/s]\n",
      "_data/influenced.sparql_Sun Mar 15 21:36:26 2020.json: 8304it [00:08, 1019.58it/s]\n"
     ]
    }
   ],
   "source": [
    "def fetch_all():\n",
    "    saved = {}\n",
    "    for name, query in zip(names, queries):\n",
    "        saved_name = save(query, name)\n",
    "        saved[name] = saved_name\n",
    "    with open('last_save.json', 'w') as f:\n",
    "        json.dump(saved, f)\n",
    "        \n",
    "fetch_all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
